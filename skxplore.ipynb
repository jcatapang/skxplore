{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skxplore\n",
    "## A top layer package for scikit-learn\n",
    "\n",
    "This scikit-learn top layer package finds the machine learning model and hyperparameters best-suited for the dataset and properties the user has set.\n",
    "\n",
    "The find_model function has the following parameters:<br>\n",
    "`dataset` takes a pandas dataframe as its value<br>\n",
    "`train_size` is a float from the interval (0, 1); it defines the partition of the dataset for training and testing<br>\n",
    "`problem` has three selections: classification, regression, and clustering<br>\n",
    "`label` takes a column name in the pandas dataframe and treats it as the label for classification or the target value for regression<br>\n",
    "`datatype` has two types: numerical and nominal (for text classification); numerical by default<br>\n",
    "`dim_reduction` takes True or False as its value; it gives the option to apply dimensionality reduction on the dataset; False by default<br>\n",
    "`features` is the number of components to remain after dimensionality reduction; auto by default<br>\n",
    "`contains_negative` takes True or False as its value; setting its value to True uses principal component analysis, while setting its value to False uses non-negative matrix factorization; True by default<br>\n",
    "`ensembling` takes True or False as its value; setting its value to True makes use of ensemble methods from base estimators, while setting its value to False disables ensembling<br>\n",
    "`priority` has two selections: accuracy and time; selecting accuracy would enable the module to find for better hyperparameters and optimize the different algorithms in consideration; selecting time would use the default hyperparameters<br>\n",
    "\n",
    "skxplore considers the following algorithms:<br>\n",
    "1. Classification<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;`Naive Bayes algorithm`, `K-nearest neighbors algorithm`, `Support vector machine classifier`, `eXtreme gradient boosting classifier`, and `Light gradient boosting machine classifier`\n",
    "2. Regression<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;`Lasso regression`, `Ridge regression`, `Elastic net regression`, `Linear regression`, `Support vector machine regressor`, `eXtreme gradient boosting regressor`, and `Light gradient boosting machine regressor`\n",
    "3. Clustering<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;`K-means clustering`, `Spectral clustering`, `Gaussian mixture model`, `Density-based spatial clustering of applications with noise (DBSCAN) algorithm`, and `Ordering points to identify the clustering structure (OPTICS) algorithm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the preprocessing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Importing the classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Importing the regressors\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Importing the clustering algorithms\n",
    "from sklearn.cluster import KMeans, SpectralClustering, DBSCAN, OPTICS\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, explained_variance_score, silhouette_score\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from IPython.display import HTML\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model(dataset, train_size, problem, label=\"\", datatype=\"numerical\",\n",
    "               dim_reduction=False, components=\"auto\", contains_negative=True, ensembling=True, priority=\"accuracy\"):\n",
    "    if datatype == \"numerical\" and problem == \"classification\":\n",
    "        # Label encode data to ensure everything is numeric\n",
    "        print(\"Label encoding. . .\")\n",
    "        dataset = dataset.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    # Splitting the dataset into the features and label\n",
    "    print(\"Identifying feature columns and label column. . .\")\n",
    "    X = dataset[dataset.columns.difference([label])] #features\n",
    "    y = dataset[label] #label\n",
    "    \n",
    "    if datatype == \"nominal\" and problem == \"classification\":\n",
    "        if dim_reduction:\n",
    "            print(\"Dimensionality reduction is not supported if your datatype is nominal.\")\n",
    "            exit()\n",
    "        else:\n",
    "            print(\"Applying term frequency inverse document frequency on text. . .\")\n",
    "            Tfidf_vect = TfidfVectorizer(max_features=2500)\n",
    "            Tfidf_vect.fit_transform(X)\n",
    "            print(\"Label encoding. . .\")\n",
    "            y = y.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    # Reduce dimensionality of dataset\n",
    "    if dim_reduction:\n",
    "        print(\"Performing dimensionality reduction. . .\")\n",
    "        print(\"Features' shape before reduction is\", X.shape)\n",
    "        if contains_negative: # If dataset contains negative values, use principal component analysis\n",
    "            if components == \"auto\":\n",
    "                print(\"Using default number of components for principal component analysis. . .\")\n",
    "                pca = PCA(n_components=2)\n",
    "            else:\n",
    "                print(\"Using\", components, \"components for principal component analysis. . .\")\n",
    "                pca = PCA(n_components=components)\n",
    "            X = pca.fit_transform(X)\n",
    "        else: # Otherwise, use non-negative matrix factorization\n",
    "            if components == \"auto\":\n",
    "                print(\"Using default number of components for non-negative matrix factorization. . .\")\n",
    "                nmf = NMF(n_components=2)\n",
    "            else:\n",
    "                print(\"Using\", components, \"components for principal component analysis. . .\")\n",
    "                nmf = NMF(n_components=components)\n",
    "            X = nmf.fit_transform(X)\n",
    "        print(\"Features' shape after reduction is\", X.shape)\n",
    "    \n",
    "    # Split X and y into training and testing datasets\n",
    "    print(\"Splitting datasets for training and testing. . .\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = train_size)\n",
    "    \n",
    "    # Scale variables to standardize values\n",
    "    print(\"Standardizing values. . .\")\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    if priority == \"accuracy\":\n",
    "        if problem == \"classification\":\n",
    "            find_classification_model(X_train, X_test, y_train, y_test, priority=\"accuracy\", ensembling=ensembling, datatype=datatype)\n",
    "        elif problem == \"regression\":\n",
    "            find_regression_model(X_train, X_test, y_train, y_test, ensembling=ensembling)\n",
    "        elif problem == \"clustering\":\n",
    "            find_clustering_model(X, y)\n",
    "        \n",
    "    if priority == \"time\":\n",
    "        if problem == \"classification\":\n",
    "            find_classification_model(X_train, X_test, y_train, y_test, priority=\"time\", ensembling=ensembling, datatype=datatype)\n",
    "        elif problem == \"regression\":\n",
    "            find_regression_model(X_train, X_test, y_train, y_test, ensembling=ensembling)\n",
    "        elif problem == \"clustering\":\n",
    "            find_clustering_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classification_model(X_train, X_test, y_train, y_test, priority=\"accuracy\", ensembling=True, datatype=\"numerical\"):\n",
    "    models = []\n",
    "    overall_accuracies = []\n",
    "    \n",
    "    if ensembling:\n",
    "        print(\"Ensembing is enabled.\")\n",
    "        # Use XGBoost\n",
    "        if priority == \"accuracy\":\n",
    "            learning_rate_list = [0.1, 0.01, 0.001]\n",
    "            gamma_list = [0, 1, 5]\n",
    "            colsample_bytree_list = [0.3, 0.5, 0.8, 1]\n",
    "            # Creating list of cv scores\n",
    "            scores = []\n",
    "            params = []\n",
    "            \n",
    "            for lr in learning_rate_list:\n",
    "                for g in gamma_list:\n",
    "                    for cb in colsample_bytree_list:\n",
    "                        xgb = XGBClassifier(learning_rate=lr, gamma=g, colsample_bytree=cb)\n",
    "                        xgb.fit(X_train, y_train)\n",
    "                        y_pred = xgb.predict(X_test)\n",
    "                        scores.append(accuracy_score(y_test, y_pred))\n",
    "                        params.append([lr, g, cb])\n",
    "            XGB_max_scores = max(scores)\n",
    "            print(\"XGBoost classifier score is:\", XGB_max_scores, \"with the following values\\nfor learning rate, g, and number of columns used by each tree:\", params[scores.index(XGB_max_scores)])\n",
    "            lr_best = params[scores.index(XGB_max_scores)][0] \n",
    "            g_best = params[scores.index(XGB_max_scores)][1]\n",
    "            cb_best = params[scores.index(XGB_max_scores)][2]\n",
    "            models.append(XGBClassifier(learning_rate=lr_best, gamma=g_best, colsample_bytree=cb_best))\n",
    "            overall_accuracies.append(XGB_max_scores)\n",
    "            \n",
    "        if priority == \"time\":\n",
    "            xgb = XGBClassifier()\n",
    "            xgb.fit(X_train, y_train)\n",
    "            y_pred = xgb.predict(X_test)\n",
    "            print(\"XGBoost classifier score is:\", accuracy_score(y_test, y_pred), \"using\\n\", xgb)\n",
    "            models.append(XGBClassifier())\n",
    "            overall_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "            \n",
    "            # Use LightGBM\n",
    "            learning_rate_list = [0.1, 0.01, 0.001]\n",
    "            objective_list = [\"binary\", \"multiclass\"]\n",
    "            colsample_bytree_list = [0.3, 0.5, 0.8, 1]\n",
    "            # Creating list of cv scores\n",
    "            scores = []\n",
    "            params = []\n",
    "            \n",
    "            for lr in learning_rate_list:\n",
    "                for o in objective_list:\n",
    "                    for cb in colsample_bytree_list:\n",
    "                        lgbm = LGBMClassifier(learning_rate=lr, objective=o, colsample_bytree=cb)\n",
    "                        lgbm.fit(X_train, y_train)\n",
    "                        y_pred = lgbm.predict(X_test)\n",
    "                        scores.append(accuracy_score(y_test, y_pred))\n",
    "                        params.append([lr, o, cb])\n",
    "            LGBM_max_scores = max(scores)\n",
    "            print(\"LightGBM classifier score is:\", LGBM_max_scores, \"with the following values\\nfor learning rate and objective:\", params[scores.index(LGBM_max_scores)])\n",
    "            lr_best = params[scores.index(LGBM_max_scores)][0] \n",
    "            o_best = params[scores.index(LGBM_max_scores)][1]\n",
    "            cb_best = params[scores.index(LGBM_max_scores)][2]\n",
    "            models.append(LGBMClassifier(learning_rate=lr_best, objective=o_best, colsample_bytree=cb_best))\n",
    "            overall_accuracies.append(LGBM_max_scores)\n",
    "            \n",
    "    else:\n",
    "        print(\"Ensembling is disabled.\")\n",
    "        \n",
    "    if priority == \"accuracy\": # If the priority is to have the highest accuracy possible\n",
    "        if datatype == \"numerical\": # If the data is numeric, use support vector machine or k-nearest neighbors\n",
    "            # Use SVM\n",
    "            # Creating lists of gamma and c for SVM\n",
    "            gamma_list = [1e-3, 1e-5, 1e-7, 1e-9]\n",
    "            c_list = [1, 10, 100, 1000]\n",
    "            kernel_list = [\"linear\", \"rbf\", \"poly\"]\n",
    "            # Creating list of cv scores\n",
    "            scores = []\n",
    "            params = []\n",
    "\n",
    "            # Perform gridsearch on SVC model\n",
    "            for c in c_list:\n",
    "                for g in gamma_list:\n",
    "                    for k in kernel_list:\n",
    "                        if ensembling:\n",
    "                            svc = AdaBoostClassifier(SVC(probability=True, gamma=g, C=c, kernel=k), n_estimators=15)\n",
    "                        else:\n",
    "                            svc = SVC(gamma=g, C=c, kernel=k)\n",
    "                        svc.fit(X_train, y_train)\n",
    "                        y_pred = svc.predict(X_test)\n",
    "                        scores.append(accuracy_score(y_test, y_pred))\n",
    "                        params.append([g, c, k])\n",
    "            SVC_max_scores = max(scores)\n",
    "            print(\"Support vector classifier score is:\", SVC_max_scores, \"with the following values\\nfor g, c, and k:\", params[scores.index(SVC_max_scores)])\n",
    "            g_best = params[scores.index(SVC_max_scores)][0]\n",
    "            c_best = params[scores.index(SVC_max_scores)][1]\n",
    "            k_best = params[scores.index(SVC_max_scores)][2]\n",
    "            if ensembling:\n",
    "                models.append(AdaBoostClassifier(SVC(probability=True, gamma=g_best, C=c_best, kernel=k_best), n_estimators=15))\n",
    "            else:\n",
    "                models.append(SVC(gamma=g_best, C=c_best, kernel=k_best))\n",
    "            overall_accuracies.append(SVC_max_scores)\n",
    "            \n",
    "            # Use KNN\n",
    "            # Creating list of neighbors for KNN\n",
    "            neighbor_list = [2, 3, 5, 10, 15, 20]\n",
    "            # Creating list of cv scores\n",
    "            scores = []\n",
    "            params = []\n",
    "            \n",
    "            # Perform gridsearch on KNN model\n",
    "            for n in neighbor_list:\n",
    "                if len(X_train[0]) <= n:\n",
    "                    if ensembling:\n",
    "                        knn = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=n), n_estimators=100)\n",
    "                    else:\n",
    "                        knn = KNeighborsClassifier(n_neighbors=n)\n",
    "                    knn.fit(X_train, y_train)\n",
    "                    y_pred = knn.predict(X_test)\n",
    "                    scores.append(accuracy_score(y_test, y_pred))\n",
    "                    params.append(n)\n",
    "            KNN_max_scores = max(scores)\n",
    "            print(\"K-nearest neighbor classifier score is:\", KNN_max_scores, \"with the k value =\", params[scores.index(KNN_max_scores)])\n",
    "            k_best = params[scores.index(KNN_max_scores)]\n",
    "            if ensembling:\n",
    "                models.append(BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=k_best), n_estimators=100))\n",
    "            else:\n",
    "                models.append(KNeighborsClassifier(n_neighbors=k_best))\n",
    "            overall_accuracies.append(KNN_max_scores)\n",
    "            \n",
    "        elif datatype == \"nominal\": # If the data is text, use naive Bayes\n",
    "            if ensembling:\n",
    "                nbc = AdaBoostClassifier(GaussianNB(), n_estimators=100)\n",
    "            else:\n",
    "                nbc = GaussianNB()\n",
    "            nbc.fit(X_train, y_train)\n",
    "            y_pred = nbc.predict(X_test)\n",
    "            NB_max_score = accuracy_score(y_test, y_pred)\n",
    "            print(\"Naive Bayes classifier score is:\", NB_max_score, \"using\\n\", nbc)\n",
    "            if ensembling:\n",
    "                models.append(AdaBoostClassifier(GaussianNB(), n_estimators=100))\n",
    "            else:\n",
    "                models.append(GaussianNB())\n",
    "            overall_accuracies.append(NB_max_score)\n",
    "\n",
    "    else: # If the priority is to have a trained classifier model quickly\n",
    "        if datatype == \"numerical\": # If the data is numeric, use support vector machine or k-nearest neighbors\n",
    "            # Use SVM\n",
    "            if ensembling:\n",
    "                svc = AdaBoostClassifier(SVC(probability=True), n_estimators=15)\n",
    "            else:\n",
    "                svc = SVC()\n",
    "            svc.fit(X_train, y_train)\n",
    "            y_pred = svc.predict(X_test)\n",
    "            print(\"Support vector classifier score is:\", accuracy_score(y_test, y_pred), \"using\\n\", svc)\n",
    "            if ensembling:\n",
    "                models.append(AdaBoostClassifier(SVC(probability=True), n_estimators=15))\n",
    "            else:\n",
    "                models.append(SVC())\n",
    "            overall_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "            \n",
    "            # Use KNN\n",
    "            if ensembling:\n",
    "                knn = BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=100)\n",
    "            else:\n",
    "                knn = KNeighborsClassifier()\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            print(\"K-nearest neighbor classifier score is:\", accuracy_score(y_test, y_pred), \"using\\n\", knn)\n",
    "            if ensembling:\n",
    "                models.append(BaggingClassifier(base_estimator=KNeighborsClassifier(), n_estimators=100))\n",
    "            else:\n",
    "                models.append(KNeighborsClassifier())\n",
    "            overall_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        elif datatype == \"nominal\": # If the data is text, use naive Bayes\n",
    "            if ensembling:\n",
    "                nbc = AdaBoostClassifier(GaussianNB(), n_estimators=100)\n",
    "            else:\n",
    "                nbc = GaussianNB()\n",
    "            nbc.fit(X_train, y_train)\n",
    "            y_pred = nbc.predict(X_test)\n",
    "            NB_max_score = accuracy_score(y_test, y_pred)\n",
    "            print(\"Naive Bayes classifier score is:\", NB_max_score, \"using\\n\", nbc)\n",
    "            if ensembling:\n",
    "                models.append(AdaBoostClassifier(GaussianNB(), n_estimators=100))\n",
    "            else:\n",
    "                models.append(GaussianNB())\n",
    "            overall_accuracies.append(NB_max_score)\n",
    "            \n",
    "    top_accuracy = max(overall_accuracies)\n",
    "    best_model = models[overall_accuracies.index(top_accuracy)]\n",
    "    print(\"\\nWith consideration of\", priority, \"as the priority, the best model found for classifying the dataset is:\\n\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "@ignore_warnings(category=FutureWarning)\n",
    "def find_regression_model(X_train, X_test, y_train, y_test, ensembling=True):\n",
    "    models = []\n",
    "    overall_accuracies = []\n",
    "    \n",
    "    if ensembling:\n",
    "        print(\"Ensembling is enabled.\")\n",
    "        learning_rate_list = [0.1, 0.01, 0.001]\n",
    "        gamma_list = [0, 1, 5]\n",
    "        colsample_bytree_list = [0.3, 0.5, 0.8, 1]\n",
    "        # Creating list of cv scores\n",
    "        scores = []\n",
    "        params = []\n",
    "\n",
    "        for lr in learning_rate_list:\n",
    "            for g in gamma_list:\n",
    "                for cb in colsample_bytree_list:\n",
    "                    xgb = XGBRegressor(learning_rate=lr, gamma=g, colsample_bytree=cb, objective=\"reg:squarederror\")\n",
    "                    xgb.fit(X_train, y_train)\n",
    "                    y_pred = xgb.predict(X_test)\n",
    "                    scores.append(explained_variance_score(y_test, y_pred))\n",
    "                    params.append([lr, g, cb])\n",
    "        XGB_max_scores = max(scores)\n",
    "        print(\"XGBoost regressor explained variance score is:\", XGB_max_scores, \"with the following values\\nfor learning rate, g, and number of columns used by each tree:\", params[scores.index(XGB_max_scores)])\n",
    "        lr_best = params[scores.index(XGB_max_scores)][0] \n",
    "        g_best = params[scores.index(XGB_max_scores)][1]\n",
    "        cb_best = params[scores.index(XGB_max_scores)][2]\n",
    "        models.append(XGBRegressor(learning_rate=lr_best, gamma=g_best, colsample_bytree=cb_best, objective=\"reg:squarederror\"))\n",
    "        overall_accuracies.append(XGB_max_scores)\n",
    "        \n",
    "        # Use LightGBM\n",
    "        learning_rate_list = [0.1, 0.01, 0.001]\n",
    "        colsample_bytree_list = [0.3, 0.5, 0.8, 1]\n",
    "        # Creating list of cv scores\n",
    "        scores = []\n",
    "        params = []\n",
    "\n",
    "        for lr in learning_rate_list:\n",
    "            for cb in colsample_bytree_list:\n",
    "                lgbm = LGBMRegressor(learning_rate=lr, colsample_bytree=cb)\n",
    "                lgbm.fit(X_train, y_train)\n",
    "                y_pred = lgbm.predict(X_test)\n",
    "                scores.append(explained_variance_score(y_test, y_pred))\n",
    "                params.append([lr, cb])\n",
    "        LGBM_max_scores = max(scores)\n",
    "        print(\"LightGBM regressor explained variance score is:\", LGBM_max_scores, \"with the following values\\nfor learning rate and objective:\", params[scores.index(LGBM_max_scores)])\n",
    "        lr_best = params[scores.index(LGBM_max_scores)][0] \n",
    "        cb_best = params[scores.index(LGBM_max_scores)][1]\n",
    "        models.append(LGBMRegressor(learning_rate=lr_best, colsample_bytree=cb_best))\n",
    "        overall_accuracies.append(LGBM_max_scores)\n",
    "        \n",
    "    else:\n",
    "        print(\"Ensembling is disabled.\")\n",
    "        alpha_list = [100, 50, 25, 10, 5, 1, 0.75, 0.5, 0.25, 0.1, 1e-5]\n",
    "        max_iter_list = [100000, 50000, 10000, 5000, 10000]\n",
    "        \n",
    "        # Use lasso regression\n",
    "        scores = []\n",
    "        params = []\n",
    "        \n",
    "        for a in alpha_list:\n",
    "            for i in max_iter_list:\n",
    "                lasso = Lasso(alpha=a, max_iter=i)\n",
    "                lasso.fit(X_train, y_train)\n",
    "                y_pred = lasso.predict(X_test)\n",
    "                scores.append(explained_variance_score(y_test, y_pred))\n",
    "                params.append([a, i])\n",
    "        lasso_max_scores = max(scores)\n",
    "        print(\"Lasso model explained variance score is:\", lasso_max_scores, \"with the values for alpha and max iterations: \", params[scores.index(lasso_max_scores)])\n",
    "        a_best = params[scores.index(lasso_max_scores)][0]\n",
    "        i_best = params[scores.index(lasso_max_scores)][1]\n",
    "        models.append(Lasso(alpha=a_best, max_iter=i_best))\n",
    "        overall_accuracies.append(lasso_max_scores)\n",
    "        \n",
    "        # Use ridge regression\n",
    "        scores = []\n",
    "        params = []\n",
    "\n",
    "        for a in alpha_list:\n",
    "            for i in max_iter_list:\n",
    "                ridge = Ridge(alpha=a, max_iter=i)\n",
    "                ridge.fit(X_train, y_train)\n",
    "                y_pred = ridge.predict(X_test)\n",
    "                scores.append(explained_variance_score(y_test, y_pred))\n",
    "                params.append([a, i])\n",
    "        ridge_max_scores = max(scores)\n",
    "        print(\"Ridge model explained variance score is:\", ridge_max_scores, \"with the values for alpha and max iterations: \", params[scores.index(ridge_max_scores)])\n",
    "        a_best = params[scores.index(ridge_max_scores)][0]\n",
    "        i_best = params[scores.index(ridge_max_scores)][1]\n",
    "        models.append(Ridge(alpha=a_best, max_iter=i_best))\n",
    "        overall_accuracies.append(ridge_max_scores)\n",
    "        \n",
    "        # Use elastic net\n",
    "        for a in alpha_list:\n",
    "            for i in max_iter_list:\n",
    "                try:\n",
    "                    elastic = ElasticNet(alpha=a, max_iter=i, l1_ratio=0.5)\n",
    "                    elastic.fit(X_train, y_train)\n",
    "                    y_pred = elastic.predict(X_test)\n",
    "                    scores.append(explained_variance_score(y_test, y_pred))\n",
    "                    params.append([a, i])\n",
    "                except:\n",
    "                    continue\n",
    "        elastic_max_scores = max(scores)\n",
    "        a_best = params[scores.index(elastic_max_scores)][0]\n",
    "        i_best = params[scores.index(elastic_max_scores)][1]\n",
    "        l1_best = 0.5\n",
    "        models.append(ElasticNet(alpha=a_best, max_iter=i_best, l1_ratio=0.5))\n",
    "        overall_accuracies.append(elastic_max_scores)\n",
    "        print(\"Elastic net regression explained variance score is:\", elastic_max_scores, \"with the values\\nfor alpha, max iterations, and l1 ratio: \", params[scores.index(elastic_max_scores)])\n",
    "        \n",
    "        # Use linear regression\n",
    "        linear = LinearRegression()\n",
    "        linear.fit(X_train, y_train)\n",
    "        y_pred = linear.predict(X_test)\n",
    "        print(\"Linear regression explained variance score is:\", explained_variance_score(y_test, y_pred), \"using\\n\", linear)\n",
    "        models.append(LinearRegression())\n",
    "        overall_accuracies.append(explained_variance_score(y_test, y_pred))\n",
    "        \n",
    "        # Use SVM\n",
    "        # Creating lists of gamma and c for SVM\n",
    "        gamma_list = [1e-3, 1e-5, 1e-7, 1e-9]\n",
    "        c_list = [1, 10, 100, 1000]\n",
    "        kernel_list = [\"linear\", \"rbf\", \"poly\"]\n",
    "        # Creating list of cv scores\n",
    "        scores = []\n",
    "        params = []\n",
    "\n",
    "        # Perform gridsearch on SVR model\n",
    "        for c in c_list:\n",
    "            for g in gamma_list:\n",
    "                for k in kernel_list:\n",
    "                    svr = SVR(gamma=g, C=c, kernel=k)\n",
    "                    svr.fit(X_train, y_train)\n",
    "                    y_pred = svr.predict(X_test)\n",
    "                    scores.append(explained_variance_score(y_test, y_pred))\n",
    "                    params.append([g, c, k])\n",
    "        SVR_max_scores = max(scores)\n",
    "        print(\"Support vector regressor explained variance score is:\", SVR_max_scores, \"with the following values\\nfor g, c, and k:\", params[scores.index(SVR_max_scores)])\n",
    "        g_best = params[scores.index(SVR_max_scores)][0]\n",
    "        c_best = params[scores.index(SVR_max_scores)][1]\n",
    "        k_best = params[scores.index(SVR_max_scores)][2]\n",
    "        models.append(SVR(gamma=g_best, C=c_best, kernel=k_best))\n",
    "        overall_accuracies.append(SVR_max_scores)\n",
    "        \n",
    "    top_accuracy = max(overall_accuracies)\n",
    "    best_model = models[overall_accuracies.index(top_accuracy)]\n",
    "    print(\"\\nThe best model found for the regression problem on the dataset is:\\n\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clustering_model(X, y):\n",
    "    models = []\n",
    "    overall_accuracies = []\n",
    "    overall_labels = []\n",
    "    \n",
    "    # Use k-means\n",
    "    scores = []\n",
    "    labels = []\n",
    "    n_list = list(range(2, 10))\n",
    "    for n in n_list:\n",
    "        kmeans_model = KMeans(n_clusters=n, random_state=1).fit(X)\n",
    "        labels.append(kmeans_model.labels_)\n",
    "        scores.append(silhouette_score(X, kmeans_model.labels_, metric='euclidean'))\n",
    "    kmeans_max_score = max(scores)\n",
    "    print(\"K-means clustering found an optimal number of \", n_list[scores.index(kmeans_max_score)], \"clusters with a silhouette score of\", kmeans_max_score)\n",
    "    models.append(KMeans(n_clusters=n_list[scores.index(kmeans_max_score)], random_state=1))\n",
    "    overall_accuracies.append(kmeans_max_score)\n",
    "    overall_labels.append(labels[scores.index(kmeans_max_score)])\n",
    "    \n",
    "    scores = []\n",
    "    labels = []\n",
    "    # Use spectral clustering\n",
    "    for n in n_list:\n",
    "        sc_model = SpectralClustering(n_clusters=n, random_state=1).fit(X)\n",
    "        labels.append(sc_model.labels_)\n",
    "        scores.append(silhouette_score(X, sc_model.labels_, metric='euclidean'))\n",
    "    sc_max_score = max(scores)\n",
    "    print(\"Spectral clustering found an optimal number of \", n_list[scores.index(sc_max_score)], \"clusters with a silhouette score of\", sc_max_score)\n",
    "    models.append(SpectralClustering(n_clusters=n_list[scores.index(sc_max_score)], random_state=1))\n",
    "    overall_accuracies.append(sc_max_score)\n",
    "    overall_labels.append(labels[scores.index(sc_max_score)])\n",
    "    \n",
    "    # Use Gaussian mixture model\n",
    "    scores = []\n",
    "    labels = []\n",
    "    clusters = []\n",
    "    comp_list = list(range(2, 10))\n",
    "    for comp in comp_list:\n",
    "        gmm = GaussianMixture(n_components=comp).fit(X)\n",
    "        predictions = gmm.predict(X)\n",
    "        labels.append(predictions)\n",
    "        clusters.append(len(set(predictions)))\n",
    "        try:\n",
    "            scores.append(silhouette_score(X, predictions, metric='euclidean'))\n",
    "        except:\n",
    "            continue\n",
    "    gmm_max_score = max(scores)\n",
    "    print(\"Gaussian mixture model found an optimal number of\", clusters[scores.index(gmm_max_score)], \"clusters with a silhouette score of\", gmm_max_score)\n",
    "    models.append(GaussianMixture(n_components=comp_list[scores.index(gmm_max_score)]))\n",
    "    overall_accuracies.append(gmm_max_score)\n",
    "    overall_labels.append(labels[scores.index(gmm_max_score)])\n",
    "    \n",
    "    scores = []\n",
    "    labels = []\n",
    "    clusters = []\n",
    "    eps_list = [0.1, 0.5, 1, 2, 5, 10, 25, 50, 100]\n",
    "    # Use DBSCAN\n",
    "    for eps in eps_list:\n",
    "        db_model = DBSCAN(eps=eps).fit(X)\n",
    "        labels.append(db_model.labels_)\n",
    "        clusters.append(len(set(db_model.labels_)))\n",
    "        try:\n",
    "            scores.append(silhouette_score(X, db_model.labels_, metric='euclidean'))\n",
    "        except:\n",
    "            continue\n",
    "    db_max_score = max(scores)\n",
    "    print(\"Density-based spatial clustering of applications with noise (DBSCAN) algorithm\\nfound an optimal number of\", clusters[scores.index(db_max_score)], \"clusters with a silhouette score of\", db_max_score)\n",
    "    models.append(DBSCAN(eps=eps_list[scores.index(db_max_score)]))\n",
    "    overall_accuracies.append(db_max_score)\n",
    "    overall_labels.append(labels[scores.index(db_max_score)])\n",
    "    \n",
    "    scores = []\n",
    "    labels = []\n",
    "    clusters = []\n",
    "    min_samples_list = list(range(5, 101, 5))\n",
    "    # Use OPTICS\n",
    "    for min_samples in min_samples_list:\n",
    "        o_model = OPTICS(min_samples=min_samples).fit(X)\n",
    "        labels.append(o_model.labels_)\n",
    "        clusters.append(len(set(o_model.labels_)))\n",
    "        try:\n",
    "            scores.append(silhouette_score(X, o_model.labels_, metric='euclidean'))\n",
    "        except:\n",
    "            continue\n",
    "    o_max_score = max(scores)\n",
    "    print(\"Ordering points to identify the clustering structure (OPTICS) algorithm\\nfound an optimal number of\", clusters[scores.index(o_max_score)], \"clusters with a silhouette score of\", o_max_score)\n",
    "    models.append(OPTICS(min_samples=min_samples_list[scores.index(o_max_score)]))\n",
    "    overall_accuracies.append(o_max_score)\n",
    "    overall_labels.append(labels[scores.index(o_max_score)])\n",
    "    \n",
    "    if db_max_score != max(overall_accuracies) and o_max_score != max(overall_accuracies):\n",
    "        top_accuracy = max(overall_accuracies)\n",
    "        best_model = models[overall_accuracies.index(top_accuracy)]\n",
    "        best_label = overall_labels[overall_accuracies.index(top_accuracy)]\n",
    "    elif db_max_score == o_max_score or db_max_score < o_max_score:\n",
    "        top_accuracy = o_max_score\n",
    "        best_model = models[4]\n",
    "        best_label = overall_labels[4]\n",
    "    elif db_max_score == max(overall_accuracies):\n",
    "        top_accuracy = db_max_score\n",
    "        best_model = models[3]\n",
    "        best_label = overall_labels[3]\n",
    "    else:\n",
    "        top_accuracy = max(overall_accuracies)\n",
    "        best_model = models[overall_accuracies.index(top_accuracy)]\n",
    "        best_label = overall_labels[overall_accuracies.index(top_accuracy)]\n",
    "    print(\"\\nThe best clustering algorithm found for the dataset is:\\n\", best_model)\n",
    "    \n",
    "    try:\n",
    "        pca = PCA(n_components=3)\n",
    "        X = pca.fit_transform(X)\n",
    "    except:\n",
    "        exit()\n",
    "    \n",
    "    fig = plt.figure(dpi=90)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    x = X[:,0]\n",
    "    y = X[:,1]\n",
    "    z = X[:,2]\n",
    "\n",
    "    ax.scatter(x, y, -z, zdir='z', c=best_label, depthshade=True, s=5)\n",
    "\n",
    "    def rotate(angle):\n",
    "        ax.view_init(azim=angle)\n",
    "\n",
    "    rot_animation = animation.FuncAnimation(fig, rotate, frames=np.arange(0, 362, 2), interval=100)\n",
    "    filename = \"clustering_animation.gif\"\n",
    "    rot_animation.save(filename, writer='imagemagick', dpi=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying feature columns and label column. . .\n",
      "Splitting datasets for training and testing. . .\n",
      "Standardizing values. . .\n",
      "K-means clustering found an optimal number of  2 clusters with a silhouette score of 0.6808136202936811\n",
      "Spectral clustering found an optimal number of  2 clusters with a silhouette score of 0.6863930543445402\n",
      "Gaussian mixture model found an optimal number of 2 clusters with a silhouette score of 0.6863930543445402\n",
      "Density-based spatial clustering of applications with noise (DBSCAN) algorithm\n",
      "found an optimal number of 3 clusters with a silhouette score of 0.6863930543445402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; trying to use <class 'matplotlib.animation.PillowWriter'> instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordering points to identify the clustering structure (OPTICS) algorithm\n",
      "found an optimal number of 2 clusters with a silhouette score of 0.6863930543445402\n",
      "\n",
      "The best clustering algorithm found for the dataset is:\n",
      " OPTICS(algorithm='auto', cluster_method='xi', eps=None, leaf_size=30,\n",
      "       max_eps=inf, metric='minkowski', metric_params=None,\n",
      "       min_cluster_size=None, min_samples=15, n_jobs=None, p=2,\n",
      "       predecessor_correction=True, xi=0.05)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing the clustering dataset\n",
    "dataset = pd.read_csv('iris.csv')\n",
    "\n",
    "# Main parameters are the dataset, training size, and problem\n",
    "find_model(dataset, 1, \"clustering\", label=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding. . .\n",
      "Identifying feature columns and label column. . .\n",
      "Performing dimensionality reduction. . .\n",
      "Features' shape before reduction is (625, 4)\n",
      "Using default number of components for principal component analysis. . .\n",
      "Features' shape after reduction is (625, 2)\n",
      "Splitting datasets for training and testing. . .\n",
      "Standardizing values. . .\n",
      "Ensembing is enabled.\n",
      "XGBoost classifier score is: 0.7393617021276596 with the following values\n",
      "for learning rate, g, and number of columns used by each tree: [0.1, 0, 1]\n",
      "Support vector classifier score is: 0.6861702127659575 with the following values\n",
      "for g, c, and k: [0.001, 100, 'poly']\n",
      "K-nearest neighbor classifier score is: 0.6436170212765957 with the k value = 20\n",
      "\n",
      "With consideration of accuracy as the priority, the best model found for classifying the dataset is:\n",
      " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "# Importing the classification dataset\n",
    "dataset = pd.read_csv('balance-scale.data')\n",
    "\n",
    "# Main parameters are the dataset, training size, and problem\n",
    "find_model(dataset, 0.7, \"classification\", label=\"label\", datatype=\"numerical\", dim_reduction=True,\n",
    "           components=\"auto\", contains_negative=True, ensembling=True, priority=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying feature columns and label column. . .\n",
      "Splitting datasets for training and testing. . .\n",
      "Standardizing values. . .\n",
      "Ensembling is disabled.\n",
      "Lasso model explained variance score is: 0.7641907554120346 with the values for alpha and max iterations:  [0.1, 100000]\n",
      "Ridge model explained variance score is: 0.7627421481790335 with the values for alpha and max iterations:  [10, 100000]\n",
      "Elastic net regression explained variance score is: 0.7627421481790335 with the values\n",
      "for alpha, max iterations, and l1 ratio:  [10, 100000]\n",
      "Linear regression explained variance score is: 0.7592556343161431 using\n",
      " LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "Support vector regressor explained variance score is: 0.8491405632486696 with the following values\n",
      "for g, c, and k: [0.001, 1000, 'rbf']\n",
      "\n",
      "The best model found for the regression problem on the dataset is:\n",
      " SVR(C=1000, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.001,\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Importing the regression problem dataset\n",
    "dataset = pd.read_csv('boston.csv')\n",
    "\n",
    "# Main parameters are the dataset, training size, and problem\n",
    "find_model(dataset, 0.8, \"regression\", label=\"medv\", dim_reduction=False,\n",
    "           components=\"auto\", contains_negative=False, ensembling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
